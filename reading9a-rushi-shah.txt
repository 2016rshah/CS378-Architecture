Paper: Data Cache Prefetching Using a Global History Buffer by Nesbit and Smith

<b>Summary:</b>

<i>Changing the underlying data structure used to support data cache prefetching algorithms from a table to a "Global History Buffer + Index Table" can lead to three significant benefits: (1) reducing stale entries (2) reconstructing a more complete history of cache misses and (3) generalizing existing approaches to make new implementations or implement multiple algoritms at once.</i>

The  new data structure stores every cache miss in a FIFO order in a Global History Buffer which is implemented as a buffer of nodes. These nodes store the address of the miss and a pointer to the next node in their corresponding linked list. These linked lists represent missed addresses generated by the same index table key (for example, the same load instruction PC). 

Using a variety of methods to traverse this data structure and initiate a data prefetches at each visit allows for the implementation of various data prefetching algorithms.

<b>My thoughts/questions/extensions:</b>

The paper makes claims about how this method generalizes other preexisting approaches, but doesn't really suggest a new approach. This is cool and a neat optimization/generalization, but makes this work pretty incremental. I would have liked to see an evaluation of a combination implementation or a new method that outperforms old methods. Without that I am skeptical of how this improves the state of the art other than simplifying implementation. 

The key insight is that in a typical matrix to store a list of linked lists you will have to waste space to overapproximate the size. This is a neat way of avoiding the overapproximation.

The Markov methods seemed like the most intimidating part of the paper, but as I was reviewing the paper I realized they are actually not a fundamental contribution, they are just used as evidence to demonstrate a point. 

The local delta correlation was particular compelling: I like them motivating example of loads that use pointer arithmetic to access a data structure. 

Stream: 0  1  2  64  65  66  128 129 ...
Delta: 	 1  1  62  1   1   62   1    ...

This seemed very promising, but the paper did not spend as much time no it as I would have liked. It says that the correlation key is a delta pair, but this does not seem sufficiently general. It will work in the contrived example, but for example, if the stride has larger gaps the delta pair no longer be sufficient. With that being said, the evaluation section does support the conclusion that PC/DC was the most effective approach. This could have been expanded and added as a fundamental contribution of the paper rather than an intermediate result. 

The conclusion mentions an interesting direction for future work: the same underlying table can support the implementation of multiple prefetching algorithms. It is unclear how useful that would be, though, because it is hard to prioritize one implementation over the other and you would need to in order to avoid causing too much cache traffic. 

The size of the circular buffer could be configured to adapt to varying memory availibility, right? For example scaled up on more expensive prefetchers, etc. What would the cost-benefit analysis look like there? What is an optimal size for the circular buffer?

<b>Unstructured thoughts/personal notes (don't read, only including for completeness sake):</b> 

Intro
===

Prefetching to hide latency between instruction time and memory access time. Hierarchy of caches solves this problem, but data is prefetched into the cache. 

Simplest methods are sequential (prefetch after every cache miss). More recent methods wait to issue prefetches until an access pattern is detected. The prefetch degree is the maximum number of cache lines prefetched in response to a single prefetch request (higher degree is necessary to hide longer memory latencies).

More recent approaches attempt to use a table indexed by something like the PC that will store information that can help investigate stride information, etc. This table is bad because it becomes stale and reserves a fixed amount of history space for each prefetch key. 

Proposed alternative called the Global History Buffer, which is a table of linked lists indexed by the prefetch key. This reduces stale history data and "allows more accurate re-construction of the history of access patterns". 

The proposed indirect method supports improved stride and correlation prefetching algorithms, so it generalizes existing approaches. 


2: Related Work 
===

Stride Prefetching (seen before), Distance Prefetching, Markov Prefetching

3:
===

Instead of storing a static amount of information for each prefetch key, use the prefetch key to point to an element in a global linked list that stores the whole miss history. Then wherever you are pointing will point to the previous miss that was also generated by the same prefetch key. The FIFO list itself is just a sequence of all the nodes. Each node is the address of the miss and a pointer to the next most recent node that was created by the same load instruction PC. The index table just points each load instruction PC to the head of its linked list. 

This data structure can be leveraged to implement existing techniques. The approaches are named as X/Y where X is the key used for localizing the miss address stream and Y is the mechanism used for detecting addressing patterns. 

The FIFO list is stored as a circular buffer. But the circular buffer is weird because it can cause invalid pointers but it isn't perfect at detecting when a pointer has become invalid? Seems hacky

The circular buffer  eliminates many of the problems associated with conventional tables. Gives priority to most recent global history. 

The index table and the GHB are sized separately. This can be more convenient because you can make the index table smaller. 

This setup can be used to create more sophisticated prefetching methods. 

One possible problem is that you have to follow two pointers rather than just one in the GHB versus the table approach 

Width versus depth prefetching in the markov model? Not really sure about this distinction

One cool pattern that this approach can prefetch is when the programmer uses pointer arithmetic to access a data structure. For example consider the addresses and delta stream below:

Stream: 0  1  2  64  65  66  128 129 ...
Delta: 	 1  1  62  1   1   62   1    ...
